{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Engenharia de Features | Feature Engineering\n\n",
    "PT-BR: Este notebook demonstra geração de novas features (polinomiais, interações, escalonamento, encoding), uso de Pipeline do scikit-learn, seleção de features, validação e visualização.\n\n",
    "EN: This notebook demonstrates generating new features (polynomial, interactions, scaling, encoding), using scikit-learn Pipelines, feature selection, validation, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\nPT-BR: Imports e configuração.\nEN: Imports and setup.\n\"\"\"\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "ROOT = Path.cwd()\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set(style='whitegrid', context='notebook')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Dados sintéticos com colunas numéricas e categóricas\n",
    "def generate_dataset(n_samples=800, random_state=42):\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=6, n_informative=4,\n",
    "                               n_redundant=0, n_repeated=0, n_classes=3,\n",
    "                               random_state=random_state)\n",
    "    df = pd.DataFrame(X, columns=[f'num_{i}' for i in range(6)])\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    df['cat_a'] = rng.choice(['A','B','C'], size=n_samples, p=[0.5,0.3,0.2])\n",
    "    df['cat_b'] = rng.choice(['X','Y'], size=n_samples)\n",
    "    # Missing em uma coluna\n",
    "    miss_idx = rng.choice(df.index, size=int(0.08*len(df)), replace=False)\n",
    "    df.loc[miss_idx, 'num_0'] = np.nan\n",
    "    df['target'] = y\n",
    "    return df\n",
    "df = generate_dataset()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Divisão treino/teste\n",
    "num_cols = [c for c in df.columns if c.startswith('num_')]\n",
    "cat_cols = ['cat_a','cat_b']\n",
    "X = df[num_cols + cat_cols].copy()\n",
    "y = df['target'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                    random_state=42, stratify=y)\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Engenharia de features numéricas\n\n",
    "PT-BR: Vamos imputar, escalar, e adicionar termos polinomiais (incluindo interações).\n\n",
    "EN: We will impute, scale, and add polynomial terms (including interactions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_poly = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=False))\n",
    "])\n",
    "# 4) Encoding categórico\n",
    "categorical_enc = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', drop=None, sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_poly, num_cols),\n",
    "    ('cat', categorical_enc, cat_cols)\n",
    "])\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Seleção de features\n\n",
    "PT-BR: Após a expansão polinomial, podemos selecionar as k melhores features por ANOVA F.\n\n",
    "EN: After polynomial expansion, we can select the top-k features using ANOVA F.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best = 25  # ajuste conforme necessário\n",
    "clf = Pipeline(steps=[\n",
    "    ('pre', preprocessor),\n",
    "    ('select', SelectKBest(score_func=f_classif, k=k_best)),\n",
    "    ('model', LogisticRegression(max_iter=2000, multi_class='auto'))\n",
    "])\n",
    "clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Validação cruzada e treino\n\n",
    "PT-BR: Usamos StratifiedKFold para avaliar a robustez do pipeline.\n\n",
    "EN: We use StratifiedKFold to evaluate the pipeline robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=None)\n",
    "print('CV mean:', cv_scores.mean().round(4), '±', cv_scores.std().round(4))\n",
    "clf.fit(X_train, y_train)\n",
    "print('Train acc:', clf.score(X_train, y_train).round(4))\n",
    "print('Test acc :', clf.score(X_test, y_test).round(4))\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Inspecionando importância/seleção (aproximada)\n\n",
    "PT-BR: Extraímos os scores do SelectKBest para visualizar as features mais relevantes.\n\n",
    "EN: We extract SelectKBest scores to visualize the most relevant features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperar nomes de features após o preprocessor\n",
    "num_feat_names = []\n",
    "# nomes originais numéricos\n",
    "num_feat_names_raw = num_cols\n",
    "poly = clf.named_steps['pre'].named_transformers_['num'].named_steps['poly']\n",
    "poly_names = poly.get_feature_names_out(num_feat_names_raw).tolist()\n",
    "# nomes categóricos após OHE\n",
    "ohe = clf.named_steps['pre'].named_transformers_['cat'].named_steps['ohe']\n",
    "cat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "all_names = poly_names + cat_names\n",
    "# Seleção\n",
    "selector = clf.named_steps['select']\n",
    "scores = selector.scores_\n",
    "selected_mask = selector.get_support()\n",
    "selected_names = np.array(all_names)[selected_mask]\n",
    "selected_scores = scores[selected_mask]\n",
    "feat_importance = (pd.DataFrame({'feature': selected_names, 'score': selected_scores})\n",
    "                   .sort_values('score', ascending=False))\n",
    "feat_importance.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Visualizações\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=feat_importance.head(15), x='score', y='feature', orient='h')\n",
    "plt.title('Top 15 features por score (ANOVA F) | Top 15 features by score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Plotly: relação de duas features selecionadas\n",
    "if len(selected_names) >= 2:\n",
    "    # Reconstruir matriz transformada para duas features escolhidas\n",
    "    X_train_trans = clf.named_steps['pre'].fit_transform(X_train, y_train)\n",
    "    X_all_names = all_names\n",
    "    df_plot = pd.DataFrame(X_train_trans, columns=X_all_names)\n",
    "    f1, f2 = selected_names[:2]\n",
    "    fig = px.scatter(df_plot, x=f1, y=f2, color=y_train.astype(str),\n",
    "                     title='Relação entre duas features selecionadas | Relation between two selected features')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Exportar artefatos\n\n",
    "PT-BR: Salvamos o dataset transformado de treino e teste (apenas para referência).\n\n",
    "EN: We save transformed train and test datasets (for reference).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path('data/processed')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "Xt_train = clf.named_steps['pre'].fit_transform(X_train, y_train)\n",
    "Xt_test = clf.named_steps['pre'].transform(X_test)\n",
    "Xt_cols = all_names\n",
    "pd.DataFrame(Xt_train, columns=Xt_cols).to_csv(out_dir / 'train_features.csv', index=False)\n",
    "pd.DataFrame(Xt_test, columns=Xt_cols).to_csv(out_dir / 'test_features.csv', index=False)\n",
    "print('Saved:', out_dir / 'train_features.csv')\n",
    "print('Saved:', out_dir / 'test_features.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PT-BR: Fim do notebook. Próximo: modelagem e tuning.\n\n",
    "EN: End of notebook. Next: modeling and tuning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
