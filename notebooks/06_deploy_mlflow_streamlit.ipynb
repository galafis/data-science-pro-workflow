{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 — Deploy de Modelos com MLflow + Streamlit/FastAPI (Bilingue)\n",
    "\n",
    "Este notebook mostra um fluxo prático e didático de: (1) treinamento e registro de experimento/modelo com MLflow; (2) servindo o modelo via Streamlit (UI) e via FastAPI (API); (3) automação de predições em batch e em tempo real; (4) monitoramento de métricas.\n",
    "\n",
    "This notebook demonstrates: (1) training and logging a model with MLflow; (2) serving it through Streamlit (UI) and FastAPI (API); (3) batch and real-time prediction automation; (4) metrics monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup / Requirements\n",
    "\n",
    "- Python >= 3.9\n",
    "- mlflow, scikit-learn, pandas, numpy, joblib, uvicorn, fastapi, streamlit\n",
    "- Opcional: docker, great_expectations, evidently para monitoramento avançado\n",
    "\n",
    "Install (locally):\n",
    "```bash\n",
    "pip install mlflow scikit-learn pandas numpy joblib fastapi uvicorn streamlit evidently\n",
    "```\n",
    "Tip: Consider using a virtualenv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports\n",
    "import os, json, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "mlflow.set_tracking_uri(\"mlruns\")  # local filesystem store\n",
    "mlflow.set_experiment(\"breast_cancer_demo\")\n",
    "print(\"MLflow Tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load data\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train + log with MLflow\n",
    "with mlflow.start_run(run_name=\"lr_baseline\") as run:\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # predictions\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "        \"f1\": float(f1_score(y_test, y_pred)),\n",
    "        \"roc_auc\": float(roc_auc_score(y_test, y_prob))\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(pipe, artifact_path=\"model\", registered_model_name=\"breast_cancer_lr\")\n",
    "    mlflow.log_dict({\"features\": list(X.columns)}, \"features.json\")\n",
    "    print(\"Run ID:\", run.info.run_id)\n",
    "    print(\"Metrics:\", metrics)\n",
    "run_id = run.info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load model for inference / Carregar modelo para inferência\n",
    "We'll demonstrate batch and real-time usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "sample = X_test.iloc[:5]  # 5 samples\n",
    "preds = loaded_model.predict(sample)\n",
    "probs = loaded_model.predict_proba(sample)[:,1]\n",
    "pd.DataFrame({\"pred\": preds, \"prob\": probs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Streamlit app (UI)\n",
    "Crie um arquivo `app_streamlit.py` e rode `streamlit run app_streamlit.py`.\n",
    "Create file `app_streamlit.py` and run `streamlit run app_streamlit.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_app = r'''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "st.set_page_config(page_title=\"Breast Cancer Inference\")\n",
    "st.title(\"Breast Cancer Model — Inference UI\")\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model(model_uri: str):\n",
    "    return mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "MODEL_URI = \"''' + """{model_uri}""" + r'''\"\n",
    "model = load_model(MODEL_URI)\n",
    "\n",
    "bc = load_breast_cancer(as_frame=True)\n",
    "df = bc.data\n",
    "st.write(\"Input features shape:\", df.shape)\n",
    "idx = st.slider(\"Pick row index\", 0, len(df)-1, 0)\n",
    "row = df.iloc[[idx]]\n",
    "pred = int(model.predict(row)[0])\n",
    "prob = float(model.predict_proba(row)[:,1][0])\n",
    "st.metric(\"Prediction\", pred)\n",
    "st.metric(\"Probability (positive)\", prob)\n",
    "'''\n",
    "with open(\"app_streamlit.py\", \"w\") as f:\n",
    "    f.write(streamlit_app)\n",
    "print(\"Wrote app_streamlit.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. FastAPI app (API)\n",
    "Crie `api.py` e rode `uvicorn api:app --reload`.\n",
    "Create `api.py` and run `uvicorn api:app --reload`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_app = r'''\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "\n",
    "app = FastAPI(title=\"Breast Cancer API\")\n",
    "MODEL_URI = \"''' + """{model_uri}""" + r'''\"\n",
    "model = mlflow.sklearn.load_model(MODEL_URI)\n",
    "\n",
    "class Item(BaseModel):\n",
    "    features: dict\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(item: Item):\n",
    "    df = pd.DataFrame([item.features])\n",
    "    pred = int(model.predict(df)[0])\n",
    "    prob = float(model.predict_proba(df)[:,1][0])\n",
    "    return {\"prediction\": pred, \"probability\": prob}\n",
    "'''\n",
    "with open(\"api.py\", \"w\") as f:\n",
    "    f.write(api_app)\n",
    "print(\"Wrote api.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch predictions / Predições em lote\n",
    "Exemplo simples de automação em batch salvando saídas como CSV.\n",
    "Simple batch automation saving outputs to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(input_df: pd.DataFrame, model_uri: str, out_path: str = \"batch_preds.csv\"):\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    probs = model.predict_proba(input_df)[:,1]\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    out = input_df.copy()\n",
    "    out[\"pred\"] = preds\n",
    "    out[\"prob\"] = probs\n",
    "    out.to_csv(out_path, index=False)\n",
    "    return out_path\n",
    "\n",
    "batch_predict(X_test, model_uri)\n",
    "pd.read_csv(\"batch_preds.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Real-time loop / Loop em tempo real\n",
    "Demonstra um loop de predições, útil para filas/event streams.\n",
    "Demonstrates a simple real-time loop for predictions (e.g., from a queue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realtime_predict(samples: pd.DataFrame, model_uri: str, sleep_s: float = 0.5, n: int = 5):\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    for i in range(min(n, len(samples))):\n",
    "        row = samples.iloc[[i]]\n",
    "        prob = float(model.predict_proba(row)[:,1][0])\n",
    "        pred = int(prob >= 0.5)\n",
    "        print({\"i\": i, \"prob\": prob, \"pred\": pred})\n",
    "        time.sleep(sleep_s)\n",
    "\n",
    "realtime_predict(X_test, model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Monitoring / Monitoramento de métricas\n",
    "- Métricas de performance (accuracy/f1/roc_auc) já logadas no MLflow.\n",
    "- Para monitoramento de dados/deriva, experimente Evidently: https://docs.evidentlyai.com/\n",
    "- Você pode agendar jobs para recalcular métricas e subir no MLflow em runs periódicos.\n",
    "\n",
    "- Performance metrics are already logged.\n",
    "- For data/quality drift, try Evidently.\n",
    "- Schedule periodic jobs to recompute and log to MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next steps / Próximos passos\n",
    "- Empacotar com Docker e publicar no Render/Heroku/Cloud Run.\n",
    "- MLflow Model Registry com stages (Staging/Production) e CI/CD.\n",
    "- Feature store e monitoração contínua.\n",
    "\n",
    "- Package with Docker and deploy to Render/Heroku/Cloud Run.\n",
    "- Use MLflow Model Registry stages and CI/CD.\n",
    "- Add feature store and continuous monitoring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
