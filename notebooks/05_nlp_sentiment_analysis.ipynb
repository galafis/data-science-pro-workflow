{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 — NLP Sentiment Analysis / Análise de Sentimento\n",
    "\n",
    "This bilingual, teaching-oriented notebook walks through an end-to-end sentiment analysis workflow. / Este notebook bilíngue e didático cobre um fluxo completo de análise de sentimento.\n",
    "\n",
    "Objectives / Objetivos:\n",
    "- Load and inspect data / Carregar e inspecionar dados\n",
    "- Text preprocessing (lowercasing, cleaning, tokenization) / Pré-processamento de texto (minúsculas, limpeza, tokenização)\n",
    "- Vectorization with TF-IDF and embeddings / Vetorização com TF-IDF e embeddings\n",
    "- Modeling with Scikit-learn pipeline and optional BERT (transformers) / Modelagem com pipeline Scikit-learn e BERT opcional (transformers)\n",
    "- Evaluation metrics and explainability (confusion matrix, ROC, PR, SHAP/LIME-like) / Métricas e interpretabilidade (matriz de confusão, ROC, PR, SHAP/LIME-like)\n",
    "- Visualizations / Visualizações\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn pandas numpy matplotlib seaborn nltk transformers torch --quiet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "stop_en = set(stopwords.words('english'))\n",
    "stop_pt = set(stopwords.words('portuguese'))\n",
    "stop_all = stop_en.union(stop_pt)\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data / Dados\n",
    "We create a small demo dataset if none provided. Replace with your dataset. / Criamos um dataset de demonstração se nenhum for fornecido. Substitua pelo seu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'text': [\n",
    "        'I love this product, it is amazing!',\n",
    "        'Terrible experience, would not recommend.',\n",
    "        'Funcionou perfeitamente, muito satisfeito.',\n",
    "        'Péssimo atendimento ao cliente.',\n",
    "        'It was okay, nothing special.',\n",
    "        'Excelente qualidade e entrega rápida!',\n",
    "        'Worst purchase ever',\n",
    "        'Bom custo-benefício, recomendo.',\n",
    "        'Not great, not terrible',\n",
    "        'Amei! Voltarei a comprar.'\n",
    "    ],\n",
    "    'label': [1,0,1,0,0,1,0,1,0,1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing / Pré-processamento\n",
    "- Lowercase, remove URLs, mentions, punctuation\n",
    "- Remove stopwords in EN/PT\n",
    "- Optional lemmatization/stemming (omitted for brevity)\n",
    "- Tokenization via simple split (demo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_RE = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "MENTION_RE = re.compile(r'@[A-Za-z0-9_]+')\n",
    "PUNCT_RE = re.compile(r'[^\w\s]')\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = URL_RE.sub('', s)\n",
    "    s = MENTION_RE.sub('', s)\n",
    "    s = PUNCT_RE.sub(' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [t for t in tokens if t not in stop_all and len(t) > 1]\n",
    "\n",
    "def preprocess_series(texts: pd.Series) -> pd.Series:\n",
    "    cleaned = texts.apply(clean_text)\n",
    "    tokens = cleaned.apply(lambda s: s.split())\n",
    "    tokens = tokens.apply(remove_stopwords)\n",
    "    return tokens.apply(lambda toks: ' '.join(toks))\n",
    "\n",
    "df['text_clean'] = preprocess_series(df['text'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation Split / Divisão de treino/validação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text_clean'], df['label'], test_size=0.25, random_state=RANDOM_STATE, stratify=df['label']\n",
    ")\n",
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Scikit-learn Pipeline / Pipeline básica Scikit-learn\n",
    "We use TF-IDF + Logistic Regression, a strong baseline. / Usamos TF-IDF + Regressão Logística, um baseline forte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=1)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE))\n",
    "])\n",
    "tfidf_lr.fit(X_train, y_train)\n",
    "y_pred = tfidf_lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics & Plots / Métricas e Gráficos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14,4))\n",
    "ConfusionMatrixDisplay.from_estimator(tfidf_lr, X_test, y_test, cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix / Matriz de Confusão')\n",
    "RocCurveDisplay.from_estimator(tfidf_lr, X_test, y_test, ax=axes[1])\n",
    "axes[1].set_title('ROC Curve')\n",
    "PrecisionRecallDisplay.from_estimator(tfidf_lr, X_test, y_test, ax=axes[2])\n",
    "axes[2].set_title('Precision-Recall')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability (quick view) / Interpretabilidade (visão rápida)\n",
    "Feature weights from Logistic Regression indicate important tokens. / Pesos da Regressão Logística indicam tokens importantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top weighted features\n",
    "vec = tfidf_lr.named_steps['tfidf']\n",
    "clf = tfidf_lr.named_steps['clf']\n",
    "feature_names = np.array(vec.get_feature_names_out())\n",
    "coefs = clf.coef_[0]\n",
    "top_pos_idx = np.argsort(coefs)[-15:][::-1]\n",
    "top_neg_idx = np.argsort(coefs)[:15]\n",
    "print('Top positive / positivos:')\n",
    "print(list(zip(feature_names[top_pos_idx], coefs[top_pos_idx])))\n",
    "print('\nTop negative / negativos:')\n",
    "print(list(zip(feature_names[top_neg_idx], coefs[top_neg_idx])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: BERT (transformers) / Opcional: BERT (transformers)\n",
    "This section shows an inference-only example for environments without GPU. / Exemplo apenas de inferência para ambientes sem GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run if transformers and torch are available.\n",
    "# from transformers import pipeline\n",
    "# clf_bert = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "# texts = ['Amei esse produto', 'Horrível e caro', 'It is okay']\n",
    "# preds = clf_bert(texts)\n",
    "# preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference helper / Função de inferência\n",
    "Utility to predict sentiment for new texts with the sklearn pipeline. / Utilitário para prever sentimento com a pipeline sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(texts):\n",
    "    texts = pd.Series(texts)\n",
    "    texts_clean = preprocess_series(texts)\n",
    "    proba = tfidf_lr.predict_proba(texts_clean)[:,1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "    return pd.DataFrame({'text': texts, 'proba_pos': proba, 'pred': pred})\n",
    "\n",
    "predict_sentiment(['Gostei bastante', 'Horrível', 'Quite decent overall'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes / Observações\n",
    "- Replace demo data with your labeled dataset. / Substitua os dados de demo pelo seu conjunto rotulado.\n",
    "- Consider class imbalance strategies (class_weight, resampling). / Considere estratégias para desbalanceamento.\n",
    "- Hyperparameter tuning with GridSearchCV or Optuna. / Faça tuning com GridSearchCV ou Optuna.\n",
    "- For production, persist pipeline with joblib and add monitoring. / Para produção, persista a pipeline com joblib e monitore.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
